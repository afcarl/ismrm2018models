# Diffusion Data Interpretation: Model-Driven

Diffusion MRI (dMRI) probes the structure of biological tissue by sensitizing the measurement to the diffusion of water molecules. The data, properly interpreted, can support different kinds of inferences about the measured tissue. One of the main analytic tools used to interpret the data are models: mathematical expressions that can match the data by adjustment of parameters.

Models are useful because they allow us to summarize the data and approximate it, and the values of the fit parameters can be used to interpret the data in light of the process or structure that generated the data. Because the expressions comprising models are generative, they can sometimes also be used to make predictions about other measurements. Over the years, researchers have proposed many different models to explain and interpret dMRI data, with a variety of different goals. In this presentation, we will contrast and compare several different kinds of models: Phenomenological models aim to accurately approximate the data, but their parameters do not necessarily map onto specific biophysical or microscopic properties of the tissue. This means that there is some ambiguity with respect to their interpretation. That said, phenomonological models, such as the diffusion tensor model (Basser et al. 1994) and diffusion kurtosis model (Jensen et al. 2005) have been very useful and are still widely used in applications of dMRI to study brain structure, its relation to cognition and behavior, and in clinical applications. Mechanistic models, on the other hand, point to specific biophysical mechanisms that affect the signal. A class of mechanistic models are mixture models that interprets the signal in each voxel as a combination of signals from different compartments in that comprise partial volumes of the voxel (Frank, 2001, 2002). For example, these models are useful for applications of dMRI in tractography, because they allow for multiple directions of fiber connections to be tracked even within a voxel. Other mixture models are used to account for multiple of sources of the signal such as modeling of perfusion and diffusion in tandem (Le Bihan et al. 1986), and accounting for partial volumes of CSF at the white-matter/CSF boundary (Pasternak et al., 2009; Hoy et al., 2014). Another class of mechanistic models exploits knowledge about the effects of microscopic structures on the diffusion of water. These microstructural models infer parameters such as the distribution of axonal diameters within a voxel (Assaf et al. 2008) or of other microstructural parameters (Ferizi et al. 2017).

Different models have different strengths and weaknesses. To compare between different models, we use a statistical learning approach, primarily relying on a cross-validation procedure: the model is fit to one part of the data and the model parameters are used to predict the signal in another part of the data. Using cross-validation, two criteria can be used to evaluate different models. The first is model parameter reliability. This quantifies the degree to which the parameters of a model vary with different measurements, and assesses whether the inferences from the model are robust to variations due to noise. The other criterion is model signal accuracy. This is the degree to which a model prediction matches the measured signal. A useful benchmark for model prediction accuracy is test-retest reliability. We introduce the relative RMSE metric (Rokem et al. 2015). If a model prediction is more accurate than test-retest reliability, this means that it captures systematic variability in the signal, and may be useful. In this case, rRMSE is smaller than 1. If a model prediction is indistinguishable from the correct model, rRMSE converges to 1/sqrt(2). 




